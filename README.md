# American Sign Language Detection ðŸ¤Ÿ

This project detects Aâ€“Z hand gestures using a webcam and converts them into text in real time using:

- Mediapipe for hand tracking
- MLPClassifier (scikit-learn) for classification
- OpenCV for webcam interaction

## ðŸ“¦ Files

- `collect_landmarks.py` â€“ Capture and save labeled hand landmarks
- `augmentation.py` â€“ Apply noise/rotation/scale augmentation to dataset
- `train_asl_model.py` â€“ Train MLP model on augmented data
- `asl_predictor.py` â€“ Run real-time webcam-based ASL prediction
- `requirements.txt` â€“ Python dependencies

## ðŸ“Š Accuracy
- **Before Augmentation**: 94.26%
- **After Augmentation**: 98.16%

## ðŸš€ Run

```bash
pip install -r requirements.txt
python asl_predictor.py
